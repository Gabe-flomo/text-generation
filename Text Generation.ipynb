{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np \n",
    "import os\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    ''' class to load models, encoders, and other methods that help in making predictions '''\n",
    "    def __init__(self):\n",
    "        self.encoder = None\n",
    "        self.model = None\n",
    "        self.sequences = None\n",
    "        self.seq_length = None\n",
    "        self.seed_text = None\n",
    "        self.encoded_seed = None\n",
    "        self.section = None\n",
    "    \n",
    "    def load_sequences(self,path, binary = True):\n",
    "        ''' function that is used to load the text sequences from either\n",
    "        a binary pickle file or a text file. returns a list of sequences \n",
    "        and the expected sequence length'''\n",
    "    \n",
    "        # checks if the file is serialized or not\n",
    "        if binary:\n",
    "            with open(path,'rb') as file:\n",
    "                # loads the sequences \n",
    "                self.sequences = pk.load(file)\n",
    "                print(f'Sequences loaded from: {path}')\n",
    "                \n",
    "        # loads the file from an unserialized format\n",
    "        else:\n",
    "            with open(path,'r') as file:\n",
    "                doc = file.read()\n",
    "                self.sequences = doc.split('\\n')\n",
    "\n",
    "        # seq_len is a vector of size 50\n",
    "        self.seq_length = len(self.sequences[0].split()) - 1\n",
    "        return self.sequences, self.seq_length\n",
    "    \n",
    "    def load_encoder(self,path):\n",
    "        with open(path,'rb') as file:\n",
    "            self.encoder = pk.load(file)\n",
    "            print(f'Encoder loaded from: {path}')\n",
    "\n",
    "        return self.encoder\n",
    "    \n",
    "    def load_network(self,path):\n",
    "        self.model = load_model(path)\n",
    "        return self.model\n",
    "    \n",
    "    def generate_seed(self,sequences = None, index = None):\n",
    "        sequences = self.sequences if sequences is None else sequences\n",
    "        if index is not None:\n",
    "            section = index\n",
    "        else:\n",
    "            section = randint(0,len(sequences[0]))\n",
    "        self.seed_text = self.sequences[section]\n",
    "        print(f'Generated from section: {section}')\n",
    "        return self.seed_text\n",
    "    \n",
    "    def pad_input_sequence(self,seed = None):\n",
    "        # the seed text must be encoded to integers using \n",
    "        # the same tokenizer that we used when training the model.\n",
    "        if self.encoder is None:\n",
    "            raise TypeError(f'Encoder can not be of type: {self.encoder}')\n",
    "        \n",
    "        # load the input sequnce \n",
    "        seed = self.seed_text if seed is None else seed\n",
    "        self.encoded_seed = self.encoder.texts_to_sequences([seed])[0]\n",
    "        # Truncate the sequence to a fixed length \n",
    "        self.encoded_seed = pad_sequences([self.encoded_seed], maxlen = self.seq_length, truncating='pre')\n",
    "        return self.encoded_seed\n",
    "    \n",
    "    def generate_sequence(self, model = None, seed = None, seq_len = None, output_len = 100, save_data = True, section = None):\n",
    "        \n",
    "        # all of the input values are set to none by default so the first step is to hanlde this\n",
    "        model = self.model if model is None else model\n",
    "        seq_len = self.seq_length if seq_len is None else seq_len\n",
    "        \n",
    "        \n",
    "        # the list that the output sequence will be loaded into\n",
    "        self.result = list()\n",
    "        self.section = section if section is not None else None\n",
    "        input_text = self.generate_seed(index = self.section) if seed is None else seed\n",
    "        \n",
    "        # generate a fixed number of words\n",
    "        for _ in range(output_len):\n",
    "            # encode the text as integer\n",
    "            encoded = self.pad_input_sequence(input_text)\n",
    "            \n",
    "            # predict probabilities for each word\n",
    "            pred = self.model.predict_classes(encoded, verbose = 0)\n",
    "            \n",
    "            # map predicted word index to word\n",
    "            predicted_word = ''\n",
    "            for word, index in self.encoder.word_index.items():\n",
    "                # check to see if the current index is the index of the predicted word\n",
    "                if index == pred:\n",
    "                    predicted_word = word\n",
    "                    break\n",
    "                    \n",
    "            # append to the input text (this is so that our next predicted word is based on the word we just predicted) +=\n",
    "            input_text += ' ' + predicted_word\n",
    "            self.result.append(predicted_word) # this list will be our newly generated sequence\n",
    "        \n",
    "        self.result = ' '.join(self.result)\n",
    "        if save_data:\n",
    "            dest = r'E:\\Documents\\My Projects\\Text Generation\\Generated Text'\n",
    "            \n",
    "            filename = input(\"Enter the filename: \")\n",
    "            self.saveIO((input_text,self.result),dest, name = filename )\n",
    "        return  self.result\n",
    "    \n",
    "    def saveIO(self, data, dest, name = None):\n",
    "        ''' This saves the input and output to a file \n",
    "        \n",
    "            dest: the file destination\n",
    "            '''\n",
    "        if len(data) != 2:\n",
    "            raise ValueError('Data must be the input and output from the model')\n",
    "        else:\n",
    "            x,y = data\n",
    "          \n",
    "        # if a filename is not privided\n",
    "        if name is not None and self.section is not None:\n",
    "            section = self.section\n",
    "            with open(os.path.join(dest,str(section)),'w') as file:\n",
    "                # save the input\n",
    "                x = str(x)\n",
    "                \n",
    "                file.write(f'Input seed: {}')\n",
    "                file.write(f'Generated text: {str(y)}') \n",
    "        else:\n",
    "            if name is None:\n",
    "                raise TypeError(f\"Name cannot be of type: {None}\")\n",
    "            \n",
    "            print(name)\n",
    "            dest = os.path.join(dest,name)\n",
    "            with open(dest,'w') as file:\n",
    "                # save the input\n",
    "                file.write(f'Input seed: {str(x)}')\n",
    "                file.write(f'Generated text: {str(y)}')\n",
    "                \n",
    "        print(f'File saved to: {dest}')\n",
    "                \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabe5\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder loaded from: E:\\Documents\\My Projects\\Text Generation\\Models\\encoder.pkl\n",
      "Sequences loaded from: E:\\Documents\\My Projects\\Text Generation\\data\\HEAM.seq\n"
     ]
    }
   ],
   "source": [
    "seq_path = r'E:\\Documents\\My Projects\\Text Generation\\data\\HEAM.seq'\n",
    "encoder_path = r'E:\\Documents\\My Projects\\Text Generation\\Models\\encoder.pkl'\n",
    "model_path = r'E:\\Documents\\My Projects\\Text Generation\\Models\\BiLSTM_Language_Generation.hdf5'\n",
    "\n",
    "# instantiate a predictor class\n",
    "p = Predictor()\n",
    "p.load_network(model_path)\n",
    "p.load_encoder(encoder_path)\n",
    "seq = p.load_sequences(seq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated from section: 72992\n",
      "287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'body budgets if their brain serves up more glucose than their body needs a quick scamper up a tree will bring their energy level back into balance humans are unique in that we can regulate the budget without moving using purely mental concepts but when this skill fails you remember that'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = p.generate_seed(sequences=seq)\n",
    "print(len(seed))\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the filename: test.txt\n",
      "test.txt\n",
      "File saved to: E:\\Documents\\My Projects\\Text Generation\\Generated Text\\test.txt\n"
     ]
    }
   ],
   "source": [
    "index = 307\n",
    "gen = p.generate_sequence(seed = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you too can categorize you have unpleasant affect when you feel ill and when you might get a parent to limit with even if you learn a few true or parent even even or influence your conceptual system from your body budget as a matter of depression your favorite promotion you other street or quick alive and if you know that your perception is highly variable your eyes with your boss your inner bag and creating your genes nevertheless you construct your experiences and corrected by your incoming sensory input your brain predicts you might have more finely based on\n"
     ]
    }
   ],
   "source": [
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
